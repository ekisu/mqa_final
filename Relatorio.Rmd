---
title: "Relatorio"
author: "Joon Hyuk Kim, Ramon Dantas de Jesus"
date: "14 de novembro de 2018"
output: html_document
---

```{r setup, include=FALSE}
library(rgl)
knitr::opts_chunk$set(echo = TRUE)
knitr::knit_hooks$set(webgl = hook_webgl)
```

## ANOVA

Nesta analise ANOVA, tentaremos ver se existe uma relação entre o ano de construção da ponte (ERECTED), e o material da qual ela foi construída:

```{r anova1, results='asis'}
# Realizar ANOVA entre ano de criação da ponte (ERECTED) e material.
data <- read.csv("data.txt", na.strings="?")
dataSubset <- subset(data, select = c("ERECTED", "MATERIAL"))
dataSubset <- dataSubset[complete.cases(dataSubset), ]
n <- nrow(dataSubset)

xlim <- c(min(dataSubset$ERECTED), max(dataSubset$ERECTED))
stripchart(dataSubset$ERECTED, method="stack", xlim=xlim)

# Primeiro, sem nenhum fator, calcular a soma de quadrados.
mediaAno <- mean(dataSubset$ERECTED)
somaTotalQuadrados <- sum((dataSubset$ERECTED - mediaAno) ^ 2)

# Depois, levar a consideração o fator ERECTED.
dadosWood <- subset(dataSubset, MATERIAL == "WOOD")
dadosIron <- subset(dataSubset, MATERIAL == "IRON")
dadosSteel <- subset(dataSubset, MATERIAL == "STEEL")
```

Para ter uma ideia de se o material tem alguma relação com o ano de construção, primeiro vejamos a distribuição dos materiais pelos anos. Os gráficos representam as pontos de madeira, ferro, e aço, respectivamente:

```{r anova2, results='asis'}
stripchart(dadosWood$ERECTED, method="stack", xlim=xlim)
stripchart(dadosIron$ERECTED, method="stack", xlim=xlim)
stripchart(dadosSteel$ERECTED, method="stack", xlim=xlim)
```

Aparenta existir uma relação, então vamos fazer a tabela ANOVA, considerando este fator:

```{r anova3, results='asis'}

mediaWood <- mean(dadosWood$ERECTED)
mediaIron <- mean(dadosIron$ERECTED)
mediaSteel <- mean(dadosSteel$ERECTED)

sqWood <- sum((dadosWood$ERECTED - mediaWood)^2)
sqIron <- sum((dadosIron$ERECTED - mediaIron)^2)
sqSteel <- sum((dadosSteel$ERECTED - mediaSteel)^2)

somaQuadradosResiduais <- sqWood + sqIron + sqSteel
somaQuadradosEntre <- somaTotalQuadrados - somaQuadradosResiduais

quadradoMedioTotal <- somaTotalQuadrados / (n - 1)
quadradoMedioEntre <- somaQuadradosEntre / 2
quadradoMedioDentro <- somaQuadradosResiduais / (n - 2 - 1)

# Montar a tabela ANOVA
tabelaAnova <- data.frame(
  liberdade = c(2, n - 2 - 1, n - 1),
  SQ = c(somaQuadradosEntre, somaQuadradosResiduais, somaTotalQuadrados),
  QM = c(quadradoMedioEntre, quadradoMedioDentro, quadradoMedioTotal),
  F = c(quadradoMedioEntre / quadradoMedioDentro, "", "")
)

rownames(tabelaAnova) <- c("Entre", "Dentro", "Total")

library(knitr)
kable(tabelaAnova, caption = "Tabela ANOVA")

print(paste("Valor de f para 2,", n - 2 - 1, ", com 95% de confiança:", qf(0.95, 2, n - 2 - 1)))
print(paste("Como este valor é menor que", quadradoMedioEntre / quadradoMedioDentro, "rejeitamos a hipótese nula."))
```

Tentamos fazer essa análise para todo par de variáveis numérica-nominal, e testamos a significância daquela relação baseados nos seus *p-values*:

```{r anova4, results='asis'}
significance <- function(x) {
  if (x <= 0.001) {
	"***"
  } else if (x <= 0.01) {
	"**"
  } else if (x <= 0.05) {
	"*"
  } else if (x <= 0.1) {
	"."
  } else {
	" "
  }
}

data <- read.csv("data.txt", na.strings="?")

numerical <- c("ERECTED", "LENGTH", "LANES")
nominal <- c("PURPOSE", "CLEAR.G", "T.OR.D", "MATERIAL", "SPAN", "REL.L", "TYPE")

pValuesMatrix <- matrix(0, nrow = length(nominal), ncol = length(numerical))
rownames(pValuesMatrix) <- nominal
colnames(pValuesMatrix) <- numerical

significanceMatrix <- matrix(0, nrow = length(nominal), ncol = length(numerical))
rownames(significanceMatrix) <- nominal
colnames(significanceMatrix) <- numerical

for (numVar in numerical) {
  for (nomVar in nominal) {
	form <- as.formula(paste(numVar, "~", paste0("`", nomVar, "`")))
	dataSubset <- subset(data, select = c(numVar, nomVar))
	dataSubset <- dataSubset[complete.cases(dataSubset), ]
    
	analysis <- aov(form, data = dataSubset)
    
	pVal <- summary(analysis)[[1]][["Pr(>F)"]][[1]]
	pValuesMatrix[nomVar, numVar] <- pVal
	significanceMatrix[nomVar, numVar] <- significance(pVal)
  }
}

library(knitr)
kable(pValuesMatrix, caption = "Matriz de p-values")
kable(significanceMatrix, caption = "Matriz de significancia.")
```

A legenda para a matriz de significância é como segue: `0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1`

Nesta tabela, podemos ver que diversos fatores têm significância com o ano de construção da ponte, tirando PURPOSE e T.OR.D (*through-or-deck*), existe uma significância fraca com LENGTH, e alguns têm significância com LANES, outros não.

## Análise de regressão simples

Nos nossos dados, existem 3 variáveis numéricas: ERECTED (ano de construção), LENGTH (tamanho da ponte), e LANES (número de pistas). Assim sendo, tentaremos ver se existe alguma relação linear entre elas, primeiro olhando os gráficos, e depois criando um modelo de regressão linear.

```{r rsimples1}
# Tentar realizar regressão simples em cima das variaveis numéricas
data <- read.csv("data.txt", na.strings="?")
dataELength <- subset(data, select = c("ERECTED", "LENGTH"))
dataELength <- dataELength[complete.cases(dataELength), ]

dataELanes <- subset(data, select = c("ERECTED", "LANES"))
dataELanes <- dataELanes[complete.cases(dataELanes), ]

dataLengthLanes <- subset(data, select = c("LENGTH", "LANES"))
dataLengthLanes <- dataLengthLanes[complete.cases(dataLengthLanes), ]
```

Após ler os dados, montaremos gráficos ERECTED x LENGTH, ERECTED x LANES e LENGTH x LANES, respectivamente:

```{r rsimples2}
plot(dataELength$ERECTED, dataELength$LENGTH, pch = 16)
plot(dataELanes$ERECTED, dataELanes$LANES, pch = 16)
plot(dataLengthLanes$LENGTH, dataLengthLanes$LANES, pch = 16)

# Escolhemos a relação LENGTH em função de ERECTED
modeloLinear <- lm(LENGTH ~ ERECTED, data = dataELength)
summary(modeloLinear)

plot(dataELength$ERECTED, dataELength$LENGTH, pch = 16)
abline(modeloLinear)
```

No final, ao analisarmos o gráfico gerado pela regressão linear, vemos que existem pontos que estão muito longes da linha, e que, no geral, eles não se aproximam tanto dela. Embora pareça haver uma tendência de aumento de tamanho ao passar dos anos, este modelo não prevê muito bem.

## Análise de Regressão Múltipla

Das três variáveis numéricas, não aparenta existir informação o bastante para justificar uma regressão múltipla. Visualmente, é possível ver isto pelo gráfico gerado abaixo.

```{r rmult1, webgl=TRUE}
library(rgl)

data <- read.csv("data.txt", na.strings="?")
dataSubset <- subset(data, select = c("ERECTED", "LENGTH", "LANES"))
dataSubset <- dataSubset[complete.cases(dataSubset), ]

plot3d(dataSubset)
```

De qualquer maneira, vamos tentar adicionar um outro fator ao modelo linear criado anteriormente (LENGTH em função de ERECTED), adicionando a variável LANES ao modelo:

```{r rmult2}
# Vamos tentar partir do modelo da regressão simples, e tentar adicionar uma outra variável (LANES).
modeloLinear <- lm(LENGTH ~ ERECTED, data = dataSubset)
modeloMultipla <- lm(LENGTH ~ ERECTED + LANES, data = dataSubset)
kable(anova(modeloLinear, modeloMultipla), caption = "Tabela ANOVA, comparando os modelos LENGTH ~ ERECTED e LENGTH ~ ERECTED + LANES")
```

O modelo com mais variáveis aparenta melhorar a previsão, diminuindo a soma de quadrados residuais, com um *p-value* relativamente pequeno.

## Análise de Componentes Principais

```{r acp}
library(psych)
data <- read.csv("data.txt", na.strings="?")
attach(data)

#definir variaveis
X<- subset(data, select = c("LOCATION","ERECTED","LENGTH","LANES"))
X<- X[complete.cases(X), ]

#descricoes estatisticas
summary(X)

#matriz de correlacao
cor(X)
```

As variáveis utilizadas para essa análise foram a localização, o ano de lançamento, a distância total e o número de linhas.

````{r acp2}
#PCA
pca1 <- princomp(X, scores=TRUE, cor=TRUE)

#descricoes estatisticas do PCA
summary(pca1)
```

Realizada a função de montar os componentes principais, podemos observar que os dois primeiros componentes são capazes de representarem, juntos, aproximadamente 75% dos dados avaliados, o que, em teoria, é grande o suficiente para se realizar uma análise dos mesmos.

````{r acp3}
#Componentes Principais
loadings(pca1)
```

É interessante observar que, entre os dois componentes, a variável que mais se destacou foi a ERECTED, ano de lançamento. Uma conclusão que poderíamos ter, portanto, sobre essa análise, é que, o ano influencia diretamente sobre a montagem de pontes, ou seja, cada vez mais próximo do presente, as pontes tendem a ser mais sofisticadas, com materiais mais resistentes, e mais práticas, com mais linhas e maior em largura. O que faz muito sentido considerando o fato de que as infraestruturas sempre tendem a evoluir. Mas para ter mais certeza, a ANOVA procura explicar a relação direta entre o ano de lançamento e outras variáveis.

```{r acp4}
#Imprimir os autovalores
plot(pca1)
screeplot(pca1, type="line", main="Scree Plot")

#Imprimir os escores
biplot(pca1)

#Rotacao VARIMAX
pca2 <- principal(X, nfactors = 2, scores=TRUE)
summary(pca2)
biplot(pca2)
```

## Análise Fatorial

```{r af}
#Inicializacao dos dados

data <- read.csv("data.txt", na.strings="?")
dataSubset <- subset(data, select = c("ERECTED", "LENGTH", "LANES"))
dados <- dataSubset[complete.cases(dataSubset), ]
summary(dados)

#Preparacao da matriz de correlacao
matriz_correlacao <- cor(dados)
print(matriz_correlacao,digits=3)

#Corgrama
library(corrplot)
corrplot(matriz_correlacao)
corrplot.mixed(matriz_correlacao, lower = "number", upper = "circle", number.cex = 0.5, tl.pos = "lt")
corrplot(matriz_correlacao, method = "square", number.cex = 0.5, addCoef.col = "black")
corrplot(matriz_correlacao, method = "circle", number.cex = 0.5, addCoef.col = "black")
```

Como podemos observar, entre as variáveis númericas do banco de dados, a variável ano de lançamento (ERECTED) é a variável que mais influencia sobre as outras variáveis, como concluído nas análises anteriores. Para garantir que essa análise está, de fato, bem calculada, realizamos o teste de esfericidade de Bartlett e o teste KMO

```{r af2}
#Teste de esfericidade de Bartlett

Bartlett.sphericity.test <- function(x)
{
  method <- "Teste de esfericidade de Bartlett"
  data.name <- deparse(substitute(x))
  x <- subset(x, complete.cases(x)) # Omitindo valores faltantes
  n <- nrow(x)
  p <- ncol(x)
  chisq <- (1-n+(2*p+5)/6)*log(det(cor(x)))
  df <- p*(p-1)/2
  p.value <- pchisq(chisq, df, lower.tail=FALSE)
  names(chisq) <- "X-squared"
  names(df) <- "df"
  return(structure(list(statistic=chisq, parameter=df, p.value=p.value,
                        method=method, data.name=data.name), class="htest"))
}
Bartlett.sphericity.test(dados)
```

Como podemos observar no teste, a nossa análise tem cerca de 44% de chance do modelo fatorial ser inapropriado, o que é um resultado pouco satisfatório, pois, pensando ao contrário, temos apenas 56% de certeza que essa técnica é apropriada. Mas ainda assim pode ser uma técnica a ser levada em conta. O teste KMO deve determinar se ela é realmente ou não.

```{r af5}
#KMO
kmo = function(x)
{
  x = subset(x, complete.cases(x))
  r = cor(x)
  r2 = r^2 
  i = solve(r) 
  d = diag(i) 
  p2 = (-i/sqrt(outer(d, d)))^2 
  diag(r2) <- diag(p2) <- 0 
  KMO = sum(r2)/(sum(r2)+sum(p2))
  MSA = colSums(r2)/(colSums(r2)+colSums(p2))
  return(list(KMO=KMO, MSA=MSA))
}

kmo_data <- kmo(dados)
print(kmo_data)
```

Como o o índice KMO, nessa análise, foi de 0.44, segundo a tabela de medida de precisão da análise, todas as análises que tenham KMO abaixo de 0.5 são inaceitáveis. Portanto, realizar uma análise fatorial é improdutiva e, assim, não deve ser mais levado em conta. 

```{r af9}
#Método dos componentes principais com a matriz de correlação amostral
acpcor <- prcomp(dados, scale = TRUE)
summary(acpcor)

plot(1:ncol(dados), acpcor$sdev^2, type = "b", xlab = "Componente",
     ylab = "Vari?ncia", pch = 20, cex.axis = 1.3, cex.lab = 1.3)

#fatores
k <- 3
carfat <- acpcor$rotation[, 1:k] %*% diag(acpcor$sdev[1:k])
colnames(carfat) <- paste("Fator", 1:k, sep = " ")
carfat

#estimação das comunalidades e das variâncias específicas
comum <- rowSums(carfat^2)
vespec <- diag(matriz_correlacao) - comum
estimat <- cbind(comum, vespec, diag(matriz_correlacao))
rownames(estimat) <- colnames(dados)
colnames(estimat) <- c("Comunalidade", "Vari?ncia ?nica", "Vari?ncia")
estimat

resid <- matriz_correlacao - (carfat %*% t(carfat) + diag(vespec))
resid

#Visando auxiliar na interpretação dos fatores, realizamos uma rotação pelo método varimax.
#A função varimax encontra-se no pacote stats.

carfatr <- varimax(carfat)
carfatr
```

Mesmo que a análise deva ser ignorada, podemos utilizar de algumas conclusões que essa análise pode fazer. A partir das informações acimas, podemos verificar que ERECTED foi a variável escolhida como a mais influenciadora, já que no primeiro fator. O que, mesmo sendo uma análise imprecisa, ainda confirma aquilo que já foi analisado anteriormente. E podemos prosseguir com a mesma linha de raciocínio para outras análises restantes. 

```{r af3}
#Plot sem rotação varimax
plot(carfat, pch = 20, col = "red", xlab = "Fator 1", ylab = "Fator 2")
text(carfat, rownames(carfat), adj = 1)

#Plot com rotação varimax
plot(carfatr$loadings, pch = 20, col = "red", xlab = "Fator 1", ylab = "Fator 2")
text(carfatr$loadings, rownames(carfat), adj = 1)
```


## Escalonamento Multidimensional

```{r multscal}
### Classical MDS
# N rows (objects) x p columns (variables)
# each row identified by a unique row name

data <- read.csv("data.txt", na.strings="?")
data <- data[complete.cases(data), ]
rownames(data) <- data[, 1]
mydata<- subset(data, select = c("LOCATION"))
d <- dist(mydata) # euclidean distances between the rows
fit <- cmdscale(d,eig=TRUE, k=2) # k is the number of dim
fit # view results

# plot solution 
x <- fit$points[,1]
y <- fit$points[,2]
plot(x, y, xlab="Coordinate 1", ylab="Coordinate 2", 
     main="Metric	MDS",	type="n")
text(x, y, labels = row.names(mydata), cex=.7)
```

Apesar de haver um mapa das localizações das pontes, uma variável que não relaciona um dado com outro dado, ou seja, fornece uma relação de distância entre elas, não é capaz de formar um gráfico de distâncias entre as variáveis, o que é o principal propósito da análise de Escalonamento Multidimensional. Pelo gráfico dado acima, cada ponto (x,y) se baseou na categoria localização de 1 a 52 fornecida pela variável LOCATION, e não representa uma relação entre esses dados. Logo, essa análise é inválida, uma vez que não há informações disponíveis para o uso apropriado dessa técnica. 

## Análise discriminante

Para a análise discriminante, tentaremos prever a variavel nominal MATERIAL partindo das variáveis numéricas ERECTED, LENGTH e LANES.

```{r ad1}
## Biblioteca com a função discriminante linear de Fisher
library(MASS)
## Dados (?iris apresenta informações sobre o conjunto de dados)
data <- read.csv("data.txt", na.strings="?")
dataSubset <- subset(data, select = c("MATERIAL", "ERECTED", "LENGTH", "LANES"))
dados <- dataSubset[complete.cases(dataSubset), ]
#analise discriminante

#install.packages('psych')
library(psych)
#mostra cof de colisão
pairs.panels(dados[2:4],
         	gap=0,
         	bg=c("red", "green", "blue")[dados$MATERIAL],
         	pch=21)
```

Esses gráficos permitiram confirmar, novamente, que existe uma pequena relação entre a variável tempo (ERECTED) e distância (LENGTH), já que, conforme o tempo passava, pontes com maiores distâncias começaram a surgir, porém isso não significava que pontes menores deixariam de ser construídas, o que faz sentido uma vez que o tempo não necessariamente determina a largura que uma ponte deve ter, quem determinaria isso seria a posição geográfica determinada, ou seja, uma ponte deve ser projetada conforme a necessidade local. Além disso, podemos observar que a variável tempo e a variável material estão fortemente relacionado, uma vez que, cada grupo de material, seja madeira, ferro ou aço, está claramente isolado e de acordo com um certo período de tempo. Como podemos observar, houve uma forte presença de pontes de madeira entre 1800 e 1850. E muitas pontes de ferro entre 1850 e 1900. E por fim, muitas pontes de aço entre 1900 até hoje, o que reafirma o que foi concluído anteriormente. 

```{r ad0}
#graphics.off()
par("mar")
par(mar=c(1,1,1,1))

# Data partition
set.seed(555)
ind <- sample(2, nrow(dados),
          	replace=TRUE,
          	prob= c(0.6, 0.4))
training <- dados[ind==1, ]
testing <- dados[ind==2, ]

# Linear discriminat analysis
library(MASS)
linear <- lda(MATERIAL~ ., data=training)
linear
```

Baseado nos coeficientes de discriminância linear, podemos observar que as duas funções discriminantes formadas se baseavam, basicamente, no tempo (ERECTED). Apesar de o número de linhas (LANES) ser a segunda maior variável em questão, seu coeficiente não representa grande parte dos dados, ou melhor, influencia muito pouco em relação ao tempo. Assim, o tempo é, de fato, a variável que mais influencia nos dados, um resultado já previsto anteriormente com as outras análises.  

```{r ad5}
attributes(linear)
linear$prior
linear$counts

#Histogram
p <- predict(linear, training) #para cada registro quando foi a previsão
# $posterior mostra a prob de cada registro para cada classe
# $x margem de erro e acerto

#mostra a separação entre os grupos
ldahist(data = p$x[, 1], g= training$MATERIAL)
ldahist(data = p$x[, 2], g=training$MATERIAL)
```

Baseado nesses dois histogramas, podemos confirmar, portanto, o fato de que o tempo influencia muito mais do que o número de linhas, pois na primeira função, onde apenas o tempo está sendo levado em conta, a distribuição da função discriminante em cada grupo está boa, com cada grupo isolado em uma posição do histograma, com menos overlapping que o segundo histograma, onde apenas a variável número de linhas é levado em conta.

```{r ad3}
# Bi-Plot
#library(devtools)
#install.packages("githubinstall")
#library(githubinstall)
#install_github("fawda123/ggord")
#gh_install_packages("ggord")
library(ggord)
ggord(linear, training$MATERIAL, ylim= c(-10, 10)) #mostra escores
```

Em particular, o gráfico acima mostra algo interessante: os grupos se colidem, e mais importante, o grupo IRON está contido completamente dentro do grupo WOOD, assim eles não são exclusivos.

```{r ad2}
#Partition plot
#install.packages("klaR")
library(klaR)
partimat(MATERIAL~., data = training, method="lda")
partimat(MATERIAL~., data = training, method="qda")

#Confusion matrix and accuracy - training data
p1 <- predict(linear, training)$class
tab <- table(Predicted = p1, Actual = training$MATERIAL)
tab
#print(paste(“Quantidade prevista (%):”, sum(diag(tab))/sum(tab)*100))

#Confusion matrix and accuracy - testing data
p2 <- predict(linear, testing)$class
tab2 <- table(Predicted = p2, Actual = testing$MATERIAL)
tab2
#print(paste(“Quantidade prevista (%):”, sum(diag(tab2))/sum(tab2)*100))
```


## Correlação Canônica

A técnica de correlação canônica busca encontrar correlações entre dois conjuntos de variáveis quantitativas. Como nosso conjunto de dados não apresenta variáveis numéricas o suficiente para realizar este tipo de análise, determinamos a técnica como desnecessária.

## Testes de Aderência (Análise de Dados Categorizados)
Para os testes de aderência, tentaremos uma simples hipótese (por falta de alternativas): de que metade das pontes é de aço, e metade não é.

```{r testeaderencia}
# H_0: a distribuição das pontes é de 50% STEEL, 50% o resto
# H_1: a distribuição não é.
data <- read.csv("data.txt", na.strings="?")
dataSubset <- subset(data, select = c("MATERIAL"))
dataSubset <- dataSubset[complete.cases(dataSubset), ]

observados <- c(length(dataSubset[dataSubset == "STEEL"]), length(dataSubset[dataSubset != "STEEL"]))
p <- c(0.5, 0.5)

chisq.test(x = observados, p=p, simulate.p.value = TRUE)
```

Como vimos, a probabilidade desses dados se adequarem a probabilidade é muito baixa, menor que o nível de significância comum, de 0.05.

## Co-clustering

```{r cc}
library(blockcluster)
data <- read.csv("data.txt", na.strings="?")
dataSubset <- subset(data, select = c("ERECTED", "LENGTH", "LANES"))
dados <- subset(data, select = c("LOCATION","ERECTED","LENGTH","LANES"))
dados <- data.matrix(data)
#usage of cocluster function in its most simplest form
out<-cocluster(dados,datatype="continuous",nbcocluster=c(2,3))
#Summarize the output results
summary(out)
#Plot the original and Co-clustered data 
plot(out)
```

Como é possível observar, a partir das variáveis fornecidas, não foi possível montar um cocluster sobre elas, uma vez que são insuficientes para formar agrupamentos independentes. Com isso, é possível afirmar que a técnica de Co-Clustering, para o nosso caso, não é uma técnica útil. 

## Random Forest

```{r rf}
require(randomForest)
require(MASS)
dataSubset <- read.csv("data.txt", na.strings="?")
dataSubset = subset(dataSubset, select = -IDENTIF)
dados <- dataSubset[complete.cases(dataSubset), ]
attach(dados)
set.seed(101)
dim(dados)

#training Sample with 300 observations

train=sample(1:nrow(dados),40)
?dados  #to search on the dataset
dados.rf = randomForest(ERECTED ~ . , data = dados , subset = train)
dados.rf
plot(dados.rf)
oob.err=double(13)
test.err=double(13)

#mtry is no of Variables randomly chosen at each split
for(mtry in 1:13) 
{
  rf=randomForest(ERECTED ~ . , data = dados , subset = train,mtry=mtry,ntree=400) 
  oob.err[mtry] = rf$mse[400] #Error of all Trees fitted
  
  pred<-predict(rf,dados[-train,]) #Predictions on Test Set for each Tree
  test.err[mtry]= with(dados[-train,], mean( (ERECTED - pred)^2)) #Mean Squared Test Error
  
  cat(mtry," ") #printing the output to the console
  
}
test.err
oob.err
matplot(1:mtry , cbind(oob.err,test.err), pch=19 , col=c("red","blue"),type="b",ylab="Mean Squared Error",xlab="Number of Predictors Considered at each Split")
legend("topright",legend=c("Out of Bag Error","Test Error"),pch=19, col=c("red","blue"))
```

## Regressão Logística





 